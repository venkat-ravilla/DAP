{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "utility-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "improved-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prime-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formed-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "international-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DADataset(Dataset):\n",
    "    \n",
    "    __label_dict = dict()\n",
    "    \n",
    "    def __init__(self, tokenizer, data, text_field = \"clean_text\", label_field=\"act_label_1\", max_len=20):\n",
    "        \n",
    "        self.text = list(data[text_field]) #data['train'][text_field]\n",
    "        self.acts = list(data[label_field]) #['train'][label_field]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "        # build/update the label dictionary \n",
    "        classes = sorted(set([item for row in self.acts for item in row]))\n",
    "        \n",
    "        for cls in classes:\n",
    "            if cls not in DADataset.__label_dict.keys():\n",
    "                DADataset.__label_dict[cls]=len(DADataset.__label_dict.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def label_dict(self):\n",
    "        return DADataset.__label_dict\n",
    "    \n",
    "    def tokenize(self, input):\n",
    "        input_encoding = self.tokenizer.encode_plus(\n",
    "            text=input,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_attention_mask=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        return input_encoding\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = self.text[index]\n",
    "        act = self.acts[index]\n",
    "        label = [DADataset.__label_dict[act] for act in self.acts[index]]\n",
    "        output1 = []\n",
    "        output2 = []\n",
    "        sample = []\n",
    "        for persona in text:\n",
    "            personalistinp=[]\n",
    "            personalistatt=[]\n",
    "            for sent in persona:\n",
    "                tkr = self.tokenize(sent)\n",
    "                personalistinp.append(tkr['input_ids'])\n",
    "                personalistatt.append(tkr['attention_mask'])\n",
    "            output1.append(personalistinp)\n",
    "            output2.append(personalistatt)\n",
    "            \n",
    "        return {\n",
    "            \"output1\":torch.tensor(output1),\n",
    "            \"output2\":torch.tensor(output2),\n",
    "            \"label\":torch.tensor(label[0], dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "integral-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tired-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"swda/swda-train.csv\", converters={'Text': eval,'DamslActTag': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "blond-foundation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>DamslActTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[Lucille Hughes.], [Okay,, Lucille, I'm on, o...</td>\n",
       "      <td>[fo_o_fw_\"_by_bc, b, sd, b, %, sd, qy, ny, aa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Okay,, Lucille, I'm on, on (( )) . -], [All ...</td>\n",
       "      <td>[b, sd, b, %, sd, qy, ny, aa, sd, b]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Lucille, I'm on, on (( )) . -], [All right,,...</td>\n",
       "      <td>[sd, b, %, sd, qy, ny, aa, sd, b, sv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[All right,, # and what, # -], [# And our top...</td>\n",
       "      <td>[b, %, sd, qy, ny, aa, sd, b, sv, sd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[# and what, # -], [# And our top-, # okay, o...</td>\n",
       "      <td>[%, sd, qy, ny, aa, sd, b, sv, sd, sd]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  [[Lucille Hughes.], [Okay,, Lucille, I'm on, o...   \n",
       "1  [[Okay,, Lucille, I'm on, on (( )) . -], [All ...   \n",
       "2  [[Lucille, I'm on, on (( )) . -], [All right,,...   \n",
       "3  [[All right,, # and what, # -], [# And our top...   \n",
       "4  [[# and what, # -], [# And our top-, # okay, o...   \n",
       "\n",
       "                                         DamslActTag  \n",
       "0  [fo_o_fw_\"_by_bc, b, sd, b, %, sd, qy, ny, aa,...  \n",
       "1               [b, sd, b, %, sd, qy, ny, aa, sd, b]  \n",
       "2              [sd, b, %, sd, qy, ny, aa, sd, b, sv]  \n",
       "3              [b, %, sd, qy, ny, aa, sd, b, sv, sd]  \n",
       "4             [%, sd, qy, ny, aa, sd, b, sv, sd, sd]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "other-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list(df['Text'])\n",
    "acts = list(df['DamslActTag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "female-strap",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1874/48167877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1874/48167877.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "label = [train_dataset.label_dict()[act] for act in acts[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stretch-retro",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1874/3350704508.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "torch.tensor([label], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "explicit-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "restricted-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input):\n",
    "        input_encoding = tokenizer.encode_plus(\n",
    "            text=input,\n",
    "            truncation=True,\n",
    "            max_length=20,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        return input_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "injured-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DADataset(Dataset):\n",
    "    \n",
    "    __label_dict = dict()\n",
    "    \n",
    "    def __init__(self, tokenizer, data, text_field = \"clean_text\", label_field=\"act_label_1\", max_len=20):\n",
    "        \n",
    "        self.text = list(data[text_field]) #data['train'][text_field]\n",
    "        self.acts = list(data[label_field]) #['train'][label_field]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "        # build/update the label dictionary \n",
    "        classes = sorted(set([item for row in self.acts for item in row]))\n",
    "        \n",
    "        for cls in classes:\n",
    "            if cls not in DADataset.__label_dict.keys():\n",
    "                DADataset.__label_dict[cls]=len(DADataset.__label_dict.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def label_dict(self):\n",
    "        return DADataset.__label_dict\n",
    "    \n",
    "    def tokenize(self, input):\n",
    "        input_encoding = self.tokenizer.encode_plus(\n",
    "            text=input,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_attention_mask=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        return input_encoding\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = self.text[index]\n",
    "        act = self.acts[index]\n",
    "        label = [DADataset.__label_dict[act] for act in self.acts[index]]\n",
    "        inputid = []\n",
    "        attention = []\n",
    "        sequencemask_fr = []\n",
    "        sequencemask_bk = []\n",
    "        for persona in text:\n",
    "            start = True\n",
    "            for sent in persona:\n",
    "                tkr = self.tokenize(sent)\n",
    "                inputid.append(tkr['input_ids'])\n",
    "                attention.append(tkr['attention_mask'])\n",
    "                sequencemask_bk.append(1)\n",
    "                if start:\n",
    "                    sequencemask_fr.append(0)\n",
    "                    start = False\n",
    "                else:\n",
    "                    sequencemask_fr.append(1)\n",
    "            sequencemask_bk[len(sequencemask_bk)-1]=0\n",
    "\n",
    "        return {\n",
    "            \"sequencemask_fr\": torch.tensor(sequencemask_fr),\n",
    "            \"sequencemask_bk\": torch.tensor(sequencemask_bk),\n",
    "            \"inputid\":torch.tensor(inputid),\n",
    "            \"attention\":torch.tensor(attention),\n",
    "            \"label\":torch.tensor(label, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "modern-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DADataset(tokenizer=tokenizer, data=df, max_len=20, text_field='Text', label_field='DamslActTag')\n",
    "drop_last = True if len(train_dataset.text) % config['batch_size'] == 1 else False  \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=False, num_workers=config['num_workers'], drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "electric-simulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequencemask_fr': tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 1]),\n",
       " 'sequencemask_bk': tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0]),\n",
       " 'inputid': tensor([[    0, 20793,  4061,  7799,     4,     2,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 33082,     6,     2,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 20793,  4061,     6,    38,   437,    15,     6,    15, 41006,\n",
       "          49087,   479,   111,     2,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  3684,   235,     6,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 10431,     8,    99,     6,   849,   111,     2,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 10431,   178,    84,   299, 20551,   849,  8578,     6,    84,\n",
       "           5674,    21,     6,   111,     2,     1,     1,     1,     1,     1],\n",
       "         [    0, 24001,    47,  1798,    84,  5674,   116,     2,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  9904,     4,     2,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  3684,   235,     6,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 24167,     4,     2,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1]]),\n",
       " 'attention': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'label': tensor([21, 11, 38, 11,  0, 38, 36, 29,  6, 38])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "maritime-partition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "y = torch.ones((10))*2\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "protected-courage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0).unsqueeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "german-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([])\n",
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(x,y):\n",
    "    print(a.size())\n",
    "    #print(b.size())\n",
    "    #print(a*b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "standing-operator",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1874/2570805236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "x.flip([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "institutional-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 10, 20))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sequences = torch.empty((0, 10, 20))\n",
    "batch_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "decent-distance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 20])\n",
      "tensor([[[0.0000e+00, 2.0793e+04, 4.0610e+03,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 3.3082e+04, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 2.0793e+04, 4.0610e+03,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 9.9040e+03, 4.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 3.6840e+03, 2.3500e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 2.4167e+04, 4.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 3.3082e+04, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 2.0793e+04, 4.0610e+03,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 3.6840e+03, 2.3500e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 3.6840e+03, 2.3500e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 2.4167e+04, 4.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 4.2903e+04, 1.2000e+01,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 2.0793e+04, 4.0610e+03,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 3.6840e+03, 2.3500e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 1.0431e+04, 8.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.4167e+04, 4.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 4.2903e+04, 1.2000e+01,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+02, 4.4430e+03,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 7.5160e+03, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 1.7080e+03, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+02, 2.1800e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.0000e+02, 2.1800e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+02, 4.3700e+02,  ..., 9.5100e+02,\n",
      "          1.1000e+01, 2.0000e+00],\n",
      "         [0.0000e+00, 4.2970e+03, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 1.7080e+03, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+02, 2.1800e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 8.1550e+03, 1.0900e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.0000e+02, 4.3700e+02,  ..., 9.5100e+02,\n",
      "          1.1000e+01, 2.0000e+00],\n",
      "         [0.0000e+00, 4.2970e+03, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 4.2970e+03, 5.1000e+01,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 1.0000e+02, 2.1800e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 8.1550e+03, 1.0900e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 8.3460e+03, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 4.2970e+03, 6.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 4.2970e+03, 5.1000e+01,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 1.0010e+04, 7.2100e+02,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for inp in train_loader:\n",
    "    count=count+1\n",
    "    batch_sequences = torch.empty((0, 10, 20))\n",
    "    for i,x in enumerate(inp['inputid']):\n",
    "        batch_sequences = torch.cat((batch_sequences, x.unsqueeze(0)), dim=0)\n",
    "    #for x,y in zip(inp['inputid'],inp['attention']):\n",
    "    #    print(y)\n",
    "    print(batch_sequences.size())\n",
    "    print(batch_sequences)\n",
    "    if count>0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "material-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "foreign-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "front-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UtteranceGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name=\"roberta-base\", hidden_size=256, bidirectional=True, num_layers=1):\n",
    "        super(UtteranceGRU, self).__init__()\n",
    "        \n",
    "        \n",
    "        # embedding layer is replaced by pretrained roberta's embedding\n",
    "        self.base = AutoModel.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "        # freeze the model parameters\n",
    "        for param in self.base.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        #self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=768, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "            input_ids.shape = [seq_sentences, seq_len]\n",
    "            attention_mask.shape = [seq_sentences, seq_len]\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        hidden_states, _ = self.base(input_ids, attention_mask) # hidden_states.shape = [batch, max_len, hidden_size]\n",
    "                \n",
    "        outputs, hidden = self.gru(hidden_states)\n",
    "                \n",
    "        return torch.cat((hidden[-2,:,:],hidden[-1,:,:]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "earlier-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonaGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name=\"roberta-base\", hidden_size=256, num_layers=2, num_classes=43, device=torch.device(\"cpu\")):\n",
    "        \n",
    "        super(PersonaGRU, self).__init__()\n",
    "        \n",
    "        self.in_features = 2*hidden_size\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # utterance encoder model\n",
    "        self.utterance_rnn = UtteranceGRU(model_name=model_name, hidden_size=hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=512,\n",
    "            hidden_size=256, \n",
    "            num_layers=1, \n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # initial hidden_states\n",
    "        self.hx = torch.randn((2, 1, hidden_size), device=self.device)\n",
    "        \n",
    "    \n",
    "    def forward(self, batch_input):\n",
    "        \"\"\"\n",
    "            x.shape = [batch, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_inputid = batch_input['inputid']\n",
    "        batch_attention = batch_input['attention']\n",
    "        batch_sequencemask_fr = batch_input['sequencemask_fr']\n",
    "        batch_sequencemask_bk = batch_input['sequencemask_bk']\n",
    "        \n",
    "        batch_sequences = torch.empty((0, 10, self.in_features), device=self.device)\n",
    "        for inputid, attention in zip(batch_inputid, batch_attention):\n",
    "            seq_of_utterance = self.utterance_rnn(input_ids=inputid, attention_mask=attention)\n",
    "            batch_sequences = torch.cat((batch_sequences, seq_of_utterance.unsqueeze(0)), dim=0)\n",
    "        \n",
    "        \n",
    "        # create an empty feature vector \n",
    "        batch_personafeatures = torch.empty((0, 10, 1024), device=self.device)      \n",
    "        \n",
    "        for seq, fr_mask, bk_mask in zip(batch_sequences, batch_sequencemask_fr, batch_sequencemask_bk): #seq\n",
    "            personafeatures_forward = torch.empty((0, self.in_features), device=self.device)\n",
    "            personafeatures_backword = torch.empty((0, self.in_features), device=self.device)\n",
    "            seq_tmp = seq.unsqueeze(0)\n",
    "            seq_rev = seq_tmp.flip([0,1])\n",
    "            backseq = seq_rev.squeeze()\n",
    "            hidden = self.hx\n",
    "            for sent, fr_hid_mask in zip(seq, fr_mask):\n",
    "                sent = sent.unsqueeze(0)\n",
    "                sent = sent.unsqueeze(0)\n",
    "                outputs, hidden = self.gru(sent, torch.where(fr_hid_mask==1, hidden, self.hx))\n",
    "                personafeatures_forward = torch.cat((personafeatures_forward, outputs.squeeze(0)), dim=0)\n",
    "            \n",
    "            hidden = self.hx\n",
    "            for sent, bk_hid_mask in zip(backseq, bk_mask):\n",
    "                sent = sent.unsqueeze(0)\n",
    "                sent = sent.unsqueeze(0)\n",
    "                outputs, hidden = self.gru(sent, torch.where(bk_hid_mask==1, hidden, self.hx))\n",
    "                personafeatures_backword = torch.cat((personafeatures_backword, outputs.squeeze(0)), dim=0)\n",
    "                \n",
    "            personafeatures_backword = personafeatures_backword.unsqueeze(0).flip([0,1])\n",
    "            personafeatures = torch.cat((personafeatures_forward, personafeatures_backword.squeeze(0)), dim=1)\n",
    "            personafeatures.size()\n",
    "            batch_personafeatures = torch.cat((batch_personafeatures, personafeatures.unsqueeze(0)), dim=0)\n",
    "            \n",
    "        return batch_personafeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "balanced-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona = PersonaGRU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "developmental-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=[]\n",
    "for inp in train_loader:\n",
    "    out = persona(inp)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "saving-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 1024])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "proved-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name=\"roberta-base\", hidden_size=256, num_layers=2, num_classes=43, device=torch.device(\"cpu\")):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.in_features = 2*hidden_size\n",
    "        \n",
    "        self.device = device\n",
    "                \n",
    "        # conversaton level rnn\n",
    "        self.persona = PersonaGRU()\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=1024,\n",
    "            hidden_size=512, \n",
    "            num_layers=1, \n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # initial hidden_states\n",
    "        self.hx = torch.randn((2, 1, hidden_size), device=self.device)\n",
    "        \n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "            x.shape = [batch, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # create an empty feature vector \n",
    "        #features = torch.empty((0, self.in_features), device=self.device)\n",
    "        output = self.persona(batch)\n",
    "            \n",
    "        encoded_hidden, hi = self.gru(output)\n",
    "        \n",
    "        return encoded_hidden, hi\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "moving-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "international-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=[]\n",
    "for inp in train_loader:\n",
    "    out = encoder(inp)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "impossible-supply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 1024])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "upset-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedAttentionDAC(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name=\"roberta-base\", hidden_size=256, num_classes=43, device=torch.device(\"cpu\")):\n",
    "        \n",
    "        super(GuidedAttentionDAC, self).__init__()\n",
    "        \n",
    "        self.in_features = 2*hidden_size\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # utterance encoder model\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "            x.shape = [batch, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        outputs, hidden = self.encoder(batch)\n",
    "        hidden = torch.cat((hidden[-2,:,:],hidden[-1,:,:]), dim=1)\n",
    "        logits = self.decoder(hidden,outputs)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "sized-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GuidedAttentionDAC()\n",
    "out=[]\n",
    "for inp in train_loader:\n",
    "    out = model(inp)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "civilian-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "adjusted-berkeley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28., 42., 27., 42., 27., 42., 28., 27., 28., 42.],\n",
       "        [42., 28., 42., 28., 42., 27., 28., 42., 28., 28.],\n",
       "        [42., 28., 42., 28., 42., 27., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 42., 28., 27., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 28., 42., 27., 28.],\n",
       "        [28., 42., 27., 42., 27., 28., 42., 27., 28., 28.],\n",
       "        [42., 28., 42., 28., 42., 27., 28., 42., 27., 28.],\n",
       "        [42., 28., 27., 42., 27., 27., 42., 28., 28., 42.],\n",
       "        [28., 42., 27., 42., 27., 28., 27., 42., 28., 28.],\n",
       "        [42., 28., 27., 27., 27., 42., 28., 27., 28., 42.],\n",
       "        [42., 28., 42., 27., 28., 42., 28., 42., 27., 28.],\n",
       "        [31., 24., 42., 27., 28., 42., 27., 28., 42., 28.],\n",
       "        [28., 27., 27., 42., 27., 28., 42., 28., 42., 28.],\n",
       "        [28., 42., 27., 27., 42., 27., 42., 28., 28., 42.],\n",
       "        [42., 28., 42., 27., 28., 42., 28., 42., 27., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 27., 28., 42., 28.],\n",
       "        [42., 28., 42., 28., 42., 27., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 42., 27., 42., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 42., 27., 42., 28., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 28., 42., 27., 28.],\n",
       "        [28., 42., 27., 42., 27., 42., 28., 27., 28., 42.],\n",
       "        [28., 42., 27., 42., 27., 27., 42., 28., 28., 42.],\n",
       "        [28., 42., 27., 42., 27., 27., 42., 28., 28., 42.],\n",
       "        [42., 28., 42., 27., 28., 42., 28., 42., 27., 28.],\n",
       "        [28., 42., 27., 27., 42., 27., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 42., 27., 42., 28., 28., 42.],\n",
       "        [28., 42., 27., 27., 42., 27., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 42., 27., 28., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 27., 28., 42., 28.],\n",
       "        [28., 42., 27., 42., 27., 42., 28., 27., 28., 42.],\n",
       "        [28., 42., 27., 42., 27., 27., 42., 28., 28., 42.],\n",
       "        [28., 42., 27., 42., 27., 27., 42., 28., 28., 42.],\n",
       "        [28., 42., 27., 27., 42., 27., 28., 42., 28., 28.],\n",
       "        [42., 42., 27., 27., 42., 27., 28., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 27., 28., 42., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 27., 28., 42., 28.],\n",
       "        [28., 42., 27., 27., 42., 27., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 42., 27., 28., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 28., 42., 27., 28.],\n",
       "        [28., 42., 27., 27., 42., 28., 27., 28., 42., 28.],\n",
       "        [42., 28., 42., 28., 42., 27., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 28., 27., 42., 28., 42., 28., 28.],\n",
       "        [42., 28., 42., 28., 42., 28., 42., 27., 28., 42.],\n",
       "        [42., 28., 42., 28., 42., 27., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 42., 27., 42., 28., 28., 42., 28.],\n",
       "        [28., 42., 28., 27., 42., 27., 28., 42., 28., 42.],\n",
       "        [42., 42., 27., 42., 27., 42., 28., 27., 28., 42.],\n",
       "        [42., 42., 28., 27., 42., 27., 42., 28., 42., 28.],\n",
       "        [28., 42., 27., 42., 27., 42., 27., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 27., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 42., 27., 42., 28., 28., 42.],\n",
       "        [42., 42., 27., 42., 27., 42., 28., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 42., 28., 42., 27., 28., 28.],\n",
       "        [42., 28., 42., 27., 42., 28., 42., 27., 28., 42.],\n",
       "        [28., 42., 27., 42., 27., 42., 28., 27., 28., 42.],\n",
       "        [28., 42., 27., 42., 27., 28., 27., 42., 28., 28.],\n",
       "        [42., 28., 42., 27., 28., 42., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 42., 28., 27., 28., 42., 28.],\n",
       "        [28., 42., 27., 28., 27., 42., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 27., 42., 28., 42., 28., 28.],\n",
       "        [28., 42., 27., 27., 42., 28., 27., 28., 42., 28.],\n",
       "        [28., 42., 27., 27., 42., 28., 27., 28., 42., 28.],\n",
       "        [28., 42., 27., 42., 27., 28., 27., 42., 28., 28.],\n",
       "        [28., 42., 27., 42., 27., 28., 42., 27., 28., 28.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "appreciated-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=43, output_size=43, num_layers=2, device=torch.device(\"cpu\")):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.sostoken = torch.tensor([[43]]*64, dtype=torch.long)\n",
    "        \n",
    "        self.embedding = nn.Embedding(44, 128)\n",
    "        \n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=128,\n",
    "            hidden_size=1024, \n",
    "            num_layers=1, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # classifier on top of feature extractor\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(in_features=2048, out_features=256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=num_classes)\n",
    "        ])\n",
    "        \n",
    "        # initial hidden_states\n",
    "        self.hx = torch.randn((1, 1, 1024), device=self.device)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, final_hidden, hidden_seq):\n",
    "        \"\"\"\n",
    "            x.shape = [batch, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        input = self.hx\n",
    "        \n",
    "        inputtoken = self.sostoken\n",
    "        logitseq = torch.empty((64, 0), device=self.device)\n",
    "        final_hidden = final_hidden.unsqueeze(0)\n",
    "        for i, x in enumerate([i for i in range(10)]):\n",
    "            embedded = self.embedding(inputtoken)\n",
    "            #embedded = self.dropout(embedded)\n",
    "            finaloutput, finalhidden = self.gru(embedded, final_hidden) \n",
    "            ctx = torch.cat((finaloutput[:,0,:], hidden_seq[:,i,:]), dim=1)\n",
    "            output = self.classifier(ctx)\n",
    "            logits = torch.argmax(output, dim=1)\n",
    "            logits = logits.unsqueeze(1)\n",
    "            #print(logitseq)\n",
    "            #print(logits)\n",
    "            logitseq = torch.cat((logitseq,logits), dim=1)\n",
    "            #print(logitseq)\n",
    "            inputtoken = logits\n",
    "            final_hidden = finalhidden\n",
    "        \n",
    "        return logitseq\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "classified-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "sitting-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "logitseqout = dec(out[1], out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "female-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 12., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 12., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 12., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 12., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 12., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
       "        [12., 13., 13., 13., 13., 13., 13., 13., 13., 13.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitseqout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "useful-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[[1,2,3],[4,5,6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "whole-clinton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "demanding-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "generous-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-president",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "happy-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(LightningModel, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.model = GuidedAttentionDAC(\n",
    "            model_name=self.config['model_name'],\n",
    "            hidden_size=self.config['hidden_size'],\n",
    "            num_classes=self.config['num_classes'],\n",
    "            device=self.config['device']\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        logits  = self.model(batch)\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(params=self.parameters(), lr=self.config['lr'])\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_data = pd.read_csv(os.path.join(self.config['data_dir'], self.config['dataset'], self.config['dataset']+\"_test.csv\"), converters={'Text': eval,'DamslActTag': eval})\n",
    "        train_dataset = DADataset(tokenizer=self.tokenizer, data=train_data, max_len=self.config['max_len'], text_field=self.config['text_field'], label_field=self.config['label_field'])\n",
    "        drop_last = True if len(train_dataset.text) % self.config['batch_size'] == 1 else False  # Drop last batch if it cointains a single sample (causes error)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=self.config['num_workers'], drop_last=drop_last)\n",
    "        return train_loader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        input_ids, attention_mask, targets = batch['input_ids'], batch['attention_mask'], batch['label'].squeeze()\n",
    "        logits = self(batch)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        acc = accuracy_score(targets.cpu(), logits.argmax(dim=1).cpu())\n",
    "        f1 = f1_score(targets.cpu(), logits.argmax(dim=1).cpu(), average=self.config['average'])\n",
    "        wandb.log({\"loss\":loss, \"accuracy\":acc, \"f1_score\":f1})\n",
    "        return {\"loss\":loss, \"accuracy\":acc, \"f1_score\":f1}\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        #valid_data = load_dataset(\"csv\", data_files=os.path.join(self.config['data_dir'], self.config['dataset'], self.config['dataset']+\"_valid.csv\"))\n",
    "        valid_data = pd.read_csv(os.path.join(self.config['data_dir'], self.config['dataset'], self.config['dataset']+\"_validation.csv\"), converters={'Text': eval,'DamslActTag': eval}) # valid has ~40k samples this is valid is same as test to run it quickely, test has ~16k samples\n",
    "        valid_dataset = DADataset(tokenizer=self.tokenizer, data=valid_data, max_len=self.config['max_len'], text_field=self.config['text_field'], label_field=self.config['label_field'])\n",
    "        drop_last = True if len(valid_dataset.text) % self.config['batch_size'] == 1 else False  # Drop last batch if it cointains a single sample (causes error)\n",
    "        valid_loader = DataLoader(dataset=valid_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=self.config['num_workers'], drop_last=drop_last)\n",
    "        return valid_loader\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, targets = batch['input_ids'], batch['attention_mask'], batch['label'].squeeze()\n",
    "        logits = self(batch)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        acc = accuracy_score(targets.cpu(), logits.argmax(dim=1).cpu())\n",
    "        f1 = f1_score(targets.cpu(), logits.argmax(dim=1).cpu(), average=self.config['average'])\n",
    "        precision = precision_score(targets.cpu(), logits.argmax(dim=1).cpu(), average=self.config['average'])\n",
    "        recall = recall_score(targets.cpu(), logits.argmax(dim=1).cpu(), average=self.config['average'])\n",
    "        return {\"val_loss\":loss, \"val_accuracy\":torch.tensor([acc]), \"val_f1\":torch.tensor([f1]), \"val_precision\":torch.tensor([precision]), \"val_recall\":torch.tensor([recall])}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_accuracy'] for x in outputs]).mean()\n",
    "        avg_f1 = torch.stack([x['val_f1'] for x in outputs]).mean()\n",
    "        avg_precision = torch.stack([x['val_precision'] for x in outputs]).mean()\n",
    "        avg_recall = torch.stack([x['val_recall'] for x in outputs]).mean()\n",
    "        wandb.log({\"val_loss\":avg_loss, \"val_accuracy\":avg_acc, \"val_f1\":avg_f1, \"val_precision\":avg_precision, \"val_recall\":avg_recall})\n",
    "        return {\"val_loss\":avg_loss, \"val_accuracy\":avg_acc, \"val_f1\":avg_f1, \"val_precision\":avg_precision, \"val_recall\":avg_recall}\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        #test_data = load_dataset(\"csv\", data_files=os.path.join(self.config['data_dir'], self.config['dataset'], self.config['dataset']+\"_test.csv\"))\n",
    "        test_data = pd.read_csv(os.path.join(self.config['data_dir'], self.config['dataset'], self.config['dataset']+\"_test.csv\"), converters={'Text': eval,'DamslActTag': eval})\n",
    "        test_dataset = DADataset(tokenizer=self.tokenizer, data=test_data, max_len=self.config['max_len'], text_field=self.config['text_field'], label_field=self.config['label_field'])\n",
    "        drop_last = True if len(test_dataset.text) % self.config['batch_size'] == 1 else False  # Drop last batch if it cointains a single sample (causes error)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=self.config['batch_size'], shuffle=False, num_workers=self.config['num_workers'], drop_last=drop_last)\n",
    "        return test_loader\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, targets = batch['input_ids'], batch['attention_mask'], batch['label'].squeeze()\n",
    "        logits = self(batch)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        acc = accuracy_score(targets.cpu(), logits.argmax(dim=1).cpu())\n",
    "        f1 = f1_score(targets.cpu(), logits.argmax(dim=1).cpu(), average=self.config['average'])\n",
    "        precision = precision_score(targets.cpu(), logits.argmax(dim=1).cpu(), average=self.config['average'])\n",
    "        recall = recall_score(targets.cpu(), logits.argmax(dim=1).cpu(), average=self.config['average'])\n",
    "        return {\"test_loss\":loss, \"test_precision\":torch.tensor([precision]), \"test_recall\":torch.tensor([recall]), \"test_accuracy\":torch.tensor([acc]), \"test_f1\":torch.tensor([f1])}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_accuracy'] for x in outputs]).mean()\n",
    "        avg_f1 = torch.stack([x['test_f1'] for x in outputs]).mean()\n",
    "        avg_precision = torch.stack([x['test_precision'] for x in outputs]).mean()\n",
    "        avg_recall = torch.stack([x['test_recall'] for x in outputs]).mean()\n",
    "        return {\"test_loss\":avg_loss, \"test_precision\":avg_precision, \"test_recall\":avg_recall, \"test_acc\":avg_acc, \"test_f1\":avg_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "gorgeous-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-anderson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crf",
   "language": "python",
   "name": "crf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
